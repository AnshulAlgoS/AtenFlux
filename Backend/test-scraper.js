import { scrapeLightweight } from './scrapers/newsOutletScraper.js';

// Test the scraper with verbose logging
console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
console.log('â•‘       ğŸ§ª AtenFlux News Outlet Scraper - Test Suite       â•‘');
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

const outletName = process.argv[2] || 'The Hindu';
const maxAuthors = parseInt(process.argv[3]) || 10;

console.log(`ğŸ“° Testing Outlet: "${outletName}"`);
console.log(`ğŸ¯ Target: ${maxAuthors} authors`);
console.log(`ğŸ”§ Mode: Full autonomous (DuckDuckGo search only, no guessing)\n`);
console.log('â”€'.repeat(60));

const startTime = Date.now();

try {
  const result = await scrapeLightweight(outletName, maxAuthors);
  
  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  
  console.log('\n' + 'â•'.repeat(60));
  console.log('ğŸ“Š FINAL RESULTS');
  console.log('â•'.repeat(60));
  console.log(`â±ï¸  Duration: ${duration}s`);
  console.log(`ğŸ“° Outlet: ${result.outlet}`);
  console.log(`ğŸŒ Website: ${result.website}`);
  console.log(`ğŸ‘¥ Authors Found: ${result.authorsCount}`);
  console.log(`ğŸ“ Authors with Data: ${result.authors?.length || 0}`);
  
  if (result.authors && result.authors.length > 0) {
    const withArticles = result.authors.filter(a => a.totalArticles > 0).length;
    const totalArticles = result.authors.reduce((sum, a) => sum + a.totalArticles, 0);
    const avgArticles = (totalArticles / result.authors.length).toFixed(1);
    
    console.log(`ğŸ“„ Total Articles: ${totalArticles}`);
    console.log(`ğŸ“Š Avg Articles/Author: ${avgArticles}`);
    console.log(`âœ… Authors with Articles: ${withArticles}/${result.authors.length}`);
    
    // Topic distribution
    const topicCounts = {};
    result.authors.forEach(author => {
      const topics = author.publicationTopics || author.topics || [];
      topics.forEach(topic => {
        topicCounts[topic] = (topicCounts[topic] || 0) + 1;
      });
    });
    
    const topTopics = Object.entries(topicCounts)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 5)
      .map(([topic, count]) => `${topic}(${count})`)
      .join(', ');
    
    console.log(`ğŸ“š Top Topics: ${topTopics || 'N/A'}`);
    
    console.log('\n' + 'â”€'.repeat(60));
    console.log('ğŸ‘¥ SAMPLE AUTHORS:');
    console.log('â”€'.repeat(60));
    
    result.authors.slice(0, 5).forEach((author, i) => {
      console.log(`\n${i + 1}. ${author.name}`);
      console.log(`   Outlet: ${author.outlet}`);
      console.log(`   Role: ${author.role || 'Journalist'}`);
      console.log(`   Articles: ${author.totalArticles}`);
      console.log(`   Topics: ${author.publicationTopics?.join(', ') || author.topics?.join(', ') || 'General'}`);
      console.log(`   Keywords: ${author.topKeywords?.slice(0, 3).join(', ') || 'N/A'}`);
      console.log(`   Influence: ${author.influenceScore || 50}/100`);
      console.log(`   Profile: ${author.profileUrl}`);
    });
    
    console.log('\n' + 'â•'.repeat(60));
    console.log('âœ… TEST PASSED - Scraper working correctly!');
    console.log('â•'.repeat(60));
    
  } else {
    console.log('\n' + 'â•'.repeat(60));
    console.log('âŒ TEST FAILED - NO AUTHORS FOUND!');
    console.log('â•'.repeat(60));
    console.log('\nğŸ” Possible Causes:');
    console.log('   1. âŒ Website uses JavaScript rendering (needs browser)');
    console.log('   2. âŒ Website blocks non-browser requests');
    console.log('   3. âŒ Articles use generic bylines (filtered out)');
    console.log('   4. âŒ Byline selectors don\'t match this outlet\'s HTML');
    console.log('   5. âŒ All author names failed validation');
    
    console.log('\nğŸ’¡ Debugging Steps:');
    console.log('   1. Check logs above for "ğŸ§ª Validation Test" output');
    console.log('   2. Look for "JSON-LD scripts" and "Meta author tags" counts');
    console.log('   3. Check if any authors were found but rejected');
    console.log('   4. Try manually visiting: ' + result.website);
  }
  
  process.exit(result.authors?.length > 0 ? 0 : 1);
  
} catch (error) {
  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  
  console.log('\n' + 'â•'.repeat(60));
  console.log('âŒ TEST FAILED - ERROR');
  console.log('â•'.repeat(60));
  console.log(`â±ï¸  Duration: ${duration}s`);
  console.log(`\nğŸ”´ Error Type: ${error.name}`);
  console.log(`ğŸ“ Message: ${error.message}`);
  
  if (error.message.includes('No valid websites found')) {
    console.log('\nğŸ’¡ This error means:');
    console.log('   - DuckDuckGo search returned no matching results');
    console.log('   - Or all results were filtered out (social media, wikis, etc.)');
    console.log('   - Or outlet name is misspelled');
    
    console.log('\nğŸ”§ Try:');
    console.log(`   1. Check spelling: "${outletName}"`);
    console.log('   2. Use full official name');
    console.log('   3. Add "news" or "newspaper" to the name');
    console.log(`   4. Manual search: https://duckduckgo.com/?q=${encodeURIComponent(outletName + ' news india')}`);
  }
  
  console.log('\nğŸ› Full Stack Trace:');
  console.log(error.stack);
  
  process.exit(1);
}
